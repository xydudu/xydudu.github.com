---

layout: default
title: Socket.io 折腾
date: 2012-08-13 

---

最近我在公司内部上线了一个服务，用于实时推送一些消息给用户，项目名为 Honey.Pusher，源码开源，且托管在 [Github](https://github.com/xydudu/Honey-pusher)。如果你有兴趣，你可以clone一份代码，有改动的话，尽管的pull request。

折腾这个项目差不多有两周整，主要依赖于 [socket.io](https://github.com/LearnBoost/socket.io) 来实现的，大部分的工作都是在服务器端的，因为 socket.io 在高并发的情况下，稳定性与可靠性其实是不高的。特别是其websocket的实现，websocket本身就是存在很多局限的，对服务端，客户端的要求都比较高，要使其实稳定的运行，还是有蛮多的工作要做的。

另外，socket.io 的作者又开发了另一个类似的实现：[engine.io](https://github.com/LearnBoost/engine.io) 应该是就socket.io的一些不足作了改进，但是我还没来得及研究，不过可以先阅读他就此写的文章：[The Realtime Engine](http://www.devthought.com/2012/07/07/the-realtime-engine/) 大概就能明白一些缘由。


此文着重要讲的当然是如何在高并发的生产环境中架构一个socket.io服务。这其实基本上就是服务器端的事了。

## Proxy Socket.io
你可能直接把nodejs listen到80端口，网站，socket.io服务都运行在此进程中。然后就可以让用户直接访问了，嗯，这其实是没有问题的。这里暂且不表。

但是更多的，你的服务器80端口是被占用掉了，于是你得想办法把socket.io的服务proxy到80端口去，以便让用户不用加难看的端口号来访问。而此时，你就会遇到一个很大的坑，因为你可能第一时间就会想到用 Nginx 来 proxy_pass。这真是一件不幸的事情，因为现在发布的Nginx是不支持websocket的。这个我不想去解释太多，因为有很多的文章都很详细的解释了，并有一些解决办法。虽然，我并不赞同你真的去使用Nginx来运行你的Socket.io。

解决Nginx Proxy Socket.io的参考：
	
* [Nginx and Socket.io](https://github.com/LearnBoost/socket.io/wiki/Nginx-and-Socket.io)
* [Reverse proxy websocket](http://www.letseehere.com/reverse-proxy-web-sockets)

文章中提到的解决办法简单来说就是使用一个nginx模块：[tcp_module](https://github.com/yaoweibin/nginx_tcp_proxy_module.git)。很可喜的，这是个中国人写的模块，就编译完后的nginx配置，我还写邮件请教过他，他也很热情的回信，很是感谢他。他回信中提到的配置在此：[nginx_tcp_module_config](https://github.com/yaoweibin/nginx_tcp_proxy_module/wiki/websocket)。

用此模块配置的关键就是你的http server端口与websocket端口是不能想同的。总之，这个方法的可操作性不高，首先，编译，配置nginx就很麻烦，而则局限性也大，基本上你的nginx上就只能跑socket.io服务了，这样的话，还不如直接socket.io listen到80来的方便与可靠。所以这种方式，我弃用了。

放弃了Nginx，我尝试着用Nodejs来自己来proxy，于是我找到了 [nodejitsu / node-http-proxy](https://github.com/nodejitsu/node-http-proxy)。可以看我的实现代码：[https://github.com/xydudu/Honey-pusher/blob/master/src/run.coffee](https://github.com/xydudu/Honey-pusher/blob/master/src/run.coffee)。

{%highlight javascript linenos%}

httpProxy = require 'http-proxy'
http = require 'http'
s = new httpProxy.HttpProxy {
    target:
        host: 'localhost'
        port: 9999
}

proxyServer = http.createServer (req, res)->
    if req.url.match /socket.io/
        s.proxyRequest req, res
    else
        res.writeHead(200, {'Content-Type': 'text/plain'})
    res.end('okay')

proxyServer.on 'upgrade', (req, socket, head)->
    s.proxyWebSocketRequest(req, socket, head)

proxyServer.listen(80)

{%endhighlight%}

这段代码就是http-proxy对外暴露80端口，然后根据url的不同分发到不同的worker来处理请求。于是把www服务与socket.io服务分开了，它们分别使用不同的端口。而用户的请求是经过run.js来进行分发的。

这样的处理是没问题的，能成功的运行，但是当并发上去后，就会发现socket.io的进程CPU与内存使用率非常的高，然后就崩溃了。这当然有服务器的问题，我使用的服务器是8核2G内存，你大可以用更好的服务器来支撑起这个服务。但是这样显然是太不负责了，因为这明显在代码上是可以做优化的。

## Cluster

前面一直是便socket.io以单线程的方式在提供着服务，此进程只占着一个CPU，当并发高时，这个CPU必然是很耗体力的。但是我们的服务器有8个核啊。所以了解nodejs的process是很有用处的，由此，你可以使用nodejs自带的cluster或者其它一些开源的库来处理这个事，比如我使用的是：[mixture](https://github.com/dshaw/mixture)。然后看我的代码: [run.coffee](https://github.com/xydudu/Honey-pusher/blob/master/new/run.coffee)

{%highlight javascript linenos%}

mix = require('mixture').mix('epic')
bouncy = require 'bouncy'
configs = require './config'
api_port = configs.apiport
socket_port = configs.socketport
node_id = 0
ports = []

sio = mix.task 'socket.io', filename: configs.sio_runner
api = mix.task 'api', filename: configs.api_runner

for i in [0..configs.numCPUs]
    socket_port = socket_port + 1
    node_id = node_id + 1
    ports.push socket_port
    sio.fork args: [socket_port, node_id]

api.fork args: [api_port]

b = bouncy (req, bounce)->
    if req.url.match /^\/socket.io/
        bounce ports[Math.random()*ports.length|0]
    else
        bounce api_port

b.listen configs.port

{%endhighlight%}

这应该很好明白，mixture负责fork出worker，我这里是根据cpu核数量来决定fork出多少个worker。当然这里的代码要注意一点，一个是sio的worker，一个是api的worker，一个负责socket.io的服务，一个是负责http的api服务，由于sio的担子较重，所以我fork了多个sio的worker，而api只是一个worker。同理，如果你的应用有的服务担子重，就多几个worker来工作。

这段代码还用到了一个bouncy的模块，这是其实也是一个proxy的功能，然后就是把请求均分给相应的worker，从而不至于某一个进程超忙，而其它的进程就闲着无事，尽最大的可能利用到多核。

其实上面这份代码大致是能较好的提供服务了，在实际环境中测试会生成如下的进程树：

	├─node run.js
  	│   │   ├─node sio.js 8881 1
  	│   │   │   └─{node}
  	│   │   ├─node sio.js 8882 2
    │	│   │   └─{node}
    │   │   ├─node sio.js 8883 3
  	│   │   │   └─{node}
  	│   │   ├─node sio.js 8884 4
  	│   │   │   └─{node}
  	│   │   ├─node sio.js 8885 5
  	│   │   │   └─{node}
  	│   │   ├─node sio.js 8886 6
  	│   │   │   └─{node}
  	│   │   ├─node sio.js 8887 7
  	│   │   │   └─{node}
  	│   │   ├─node sio.js 8888 8
  	│   │   │   └─{node}
  	│   │   ├─node sio.js 8889 9
  	│   │   │   └─{node}
  	│   │   ├─node api.js 8800
  	│   │   │   └─{node}
  	│   │   └─{node}

sio有9个进程，api开了一个进程，这是没有问题的，因为sio工作重，api工作较闲。但是有要注意的是run.js这个master进程，本来这应该只是一个管理子进程的，但是由于做了一个proxy，就是如下的代码：

{%highlight javascript linenos%}

	b = bouncy (req, bounce)->
    	if req.url.match /^\/socket.io/
        	bounce ports[Math.random()*ports.length|0]
    	else
        	bounce api_port

	b.listen configs.port

{%endhighlight%}

这是做了一个分配请求的功能，这就造成了瓶颈，所有的请求都必须从此而过，并根据url来分配到相应worker，于是在这master进程在高并发的情况下，cpu占用急剧的升高。终于，纯nodejs来实现这个还是不太靠谱的。于是我决定试用一下 [HAProxy](http://haproxy.org/)。

## HAProxy

其实我要用HAProxy来实现的功能非常简单，就是上面 bouncy实现的那部分功能：把请求根据url均分给相应的worker。我的config如下：

	global
        maxconn 4096

	defaults
        mode http
        timeout connect 5s
        timeout client 5s
        timeout server 60s

	frontend all 0.0.0.0:80
        timeout client 24h
        default_backend www_backend
        option http-server-close
        option http-pretend-keepalive
        acl is_websocket hdr(upgrade) -i websocket
        acl is_websocket hdr_beg(host) -i ws
        acl is_sio path_beg /socket.io

        use_backend socket_backend if is_sio

	backend www_backend
        balance roundrobin
        option forwardfor # This sets X-Forwarded-For
        timeout server 5000
        timeout connect 4000
        server server1 localhost:8800 weight 1 maxconn 1024 check

	backend socket_backend
        option forwardfor
        balance source
        no option httpclose
        option http-server-close
        option forceclose
        timeout server 24h
        timeout connect 24h
        timeout queue 5000
        server nodejs1 127.0.0.1:8871 weight 1 maxconn 1024 check
		# more nodejs server …

这个配置有一些问题就是timeout的问题，但是我现在还没搞明白，希望有人能指点一二，到底，对于HAProxy我还是没有接触过的。


但是经过这么个折腾，honey.pusher已经很好的运行在了正式环境中。
